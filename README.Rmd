---
title: "Evaluating the predictive value of affective weights to life-events"
output: 
  github_document:
    df_print: kable
bibliography: src/references.bib
csl: src/apa-6th-edition.csl
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      fig.path = "results/")

library(tidyverse)
library(yardstick)
library(quantreg)
library(broom)
library(flextable)
library(patchwork)

source("~/Documents/R/helpers.R")

prettynum <- function(.x) {
  formatC(.x, big.mark = ",")
}
```

Extension and validation of stressful life events schedule

<br>

Instruments for measuring the severity of psychological distress resulting from recent life experiences were originally developed in the 1960s, and are used by clinicians today to identify and predict sources of patient stress. The instrument consists of a checklist containing a list of major life events (e.g., divorce, bankruptcy, death of a loved one), and a weighting is assigned to each item that was determined by asking research volunteers to anticipate the severity of stress that was expected from its occurrence. However people are notoriously poor at anticipating their emotional reaction to abstract events, and large population-based surveys can now provide data which tracks self-reported affective responses and distress levels after survey respondants have experienced the life event. This provides an opportunity to calculate weights based on the experienced affect rather than anticipated feelings, and so can provide a way to base  predictions on empirical evidence. Our other work [@kettlewell2020differential] has determined the causal effect of major life events on affective wellbeing (mental health), and so the present report evaluates and compares the predictive value of a weighted life-events scale against an unweighted summed score. 

<br>

#### Background    

Stressful life events have been identified as a risk factor for a variety of physical and mental illnesses such as cardiovascular disease, cancer, metabolic syndrome, and depression [@bahri2019relation; @kessler1997effects; @slopen2011sex]. Today, clinicians and researchers often assesses the impact of life-events through summed checklists that treat events as equal  [@dohrenwend2006inventorying; @gray2004psychometric; @wethington1995interview]. For example, the Life Events Checklist (LEC) [@gray2004psychometric] is a checklist of events which are associated with the aetiology of PTSD; responders must indicate the degree of exposure (e.g., directly experienced vs witnessed vs heard about), but the LEC does not distinguish the amount of distress from the event itself. A key feature of such checklists is that all life events are treated as equivalent, along with the implicit assumption that different life events have equivalent impacts on distress.  

The original instrument to measure life events was Holmes and Rahe’s Social Readjustment Rating Scale (SRRS) [@holmes1967social], and this included weights to distinguish and quantify the amount of stress associated with each event. The publication of the SRRS led to an enormous amount of research on the relationship between life events and various types of illness onset (typically screening scales of nonspecific psychological distress), with over 1000 papers using the SRRS published in the first decade after its development [@holmes1979development; @kessler1997effects]. It's reputed advance was in adapting the psychophysical procedure of magnitude estimation to quantify the stressfulness of an event [@dohrenwend1974stressful], which was entirely based on the amount of stress anticipated by research volunteers when imagining the event. Subsequent methodological critiques pointed out the limitations of this method [@dohrenwend1974stressful; @zimmerman1983methodological]; and within the set of fairly serious events included in SRRS life event checklists, the use of differential weights does not markedly increase the association between life event scales and measures of distress [@tibubos2021frequency; @zimmerman1983methodological]. Thus it is not clear whether and how operationalization of a differential weight improves the predictive value of life events checklists over and above frequency or the sum of exposure, and this widely appreciated limitation has led to the proliferation of summed checklists [@turner1997checklist; but see @brugha1985list].  

*(from Coyne & Downey, 1991. Ann. Rev. Psychology)*  
Whereas both minor and major life events are related to increases in depressive symptoms, it appears that only serious life events requiring long-term adjustment predict subsequent clinical depression (Brown & Harris 1978). Thus, if one is interested in predicting depressive symptoms, stronger correlations are obtained with a broad sampling of major and minor events, and current life-event inventories seem to have adopted a philosophy of "more is better." Yet only about a dozen items on a typical inventory are consistently related to clinical depression (Dohrenwend et al 1986), and broader samplings of events produce an underestimate of the strong association found with the dirty dozen. Brugha et al (1985) found that 12 of 67 categories of life events accounted for 77% of the events with etiological significance and that these events alone entailed greater relative risk for depression than the full list.

Our earlier research on the impact of major life events in affective wellbeing in a large population-based survey of Australian households between 2001 and 2016 clearly showed that different life events have empirically different impacts on affective wellbeing and mental health [@kettlewell2020differential]. Events such as divorce, major financial loss (e.g., bankruptcy) and death of a loved one (spouse or child) had much larger effects on self-reported affective wellbeing 3 to 12 months later than events such as losing employment (e.g., fired), moving home, or even home destroyed in natural disaster, consistent with @brugha1985list and @brugha1990list. Furthermore, some events had a beneficial impact on affective wellbeing, such as marriage or pregnancy. In general, our results based on reported experience are consistent with methodological studies of the SRRS (and the various checklists based on it) demonstrating that negative events are much more powerful predictors of mental health outcomes than positive events [@zautra1983life; @thoits1983dimensions]. It is therefore valuable to clinicians and researchers to provide a weighted index of life events, based on experience rather than (poorly) anticipated consequences, since highly stressful events are assumed to be a cause or risk factor for mental illness such as depression and anxiety.  


<br><br>

#### Aims  

Our primary aim was to compare the predictive value of using weighted life events relative to unweighted summed scores. We estimated the predictive value of the weighted and unweighted scores for risk of mental illness within the 12-months after the event. Risk of mental illness was defined by low mental health (MHi-5 < 64) or high psychological distress [K10 > 21]. While neither is a diagnostic instrument, the probability is high that those who score beyond the cut-point have a common mental disorder [i.e., over 85%, @andrews2001interpreting; @hoeymans2004measuring], and they have good psychometric properties when identifying DSM disorders in a community sample [AUC 0.877, @batterham2018assessing; @rumpf2001screening].   


The weights were the coefficients of risk estimated by logistic regression from a (random) split-sample of respondents in the HILDA survey over the entire sample (from 2001 to 2020) (*N* = 10,030). Each regression included all life-events and wave controls, and so the weights represent the _unique_ risk (log odds) of each life event. Predictive performance was assessed by measures of calibration and discrimination, according to TRIPOD guidelines [@collins2015transparent; @moons2015transparent].  

In addition, we conducted linear regressions and report the amount of (linear) change in the underlying scales (K10 and MHi-5) predicted by each life event at different quartiles of the response, as a way of showing how risk of mental illness may vary as a function of baseline mental health.  


<br><br>

## Methods  

<br>

#### Life events  

We select all 22 major life events in the HILDA dataset, which encompasses the two decade period from 2001 to 2020.   

To describe the frequencies and probabilities of mental illness and life events in the sample, we first calculated the probability of mental illness risk after each life event for each year. These probabilities are the $P(illness | Life event)$, and so are not adjusted for any other life-events. That is, they represent the _total_ (unconditional?) mental health risk of each life-event in each year. However the HILDA population-weights were applied in the calculation, so they are the population-weighted probability in the HILDA sample.  

```{r import-events}
# import all available event observations
events <- read_rds("data/lifeevents_by_all_years.rds") %>%
  mutate(across(lebth:levio, ~replace_na(., 0))) %>%
  mutate(All = rowSums(select(., lebth:levio), na.rm=T))

demographics <- read_rds("data/demographics_by_mhi5.rds")

named_events <- list(
  Widowed = "ledsc",    
  Divorced = "lesep",
  Bankruptcy = "lefnw",
  Jailed = "lejls",
  Attacked = "levio",
  Injured = "leins",
  Reconciled = "lercl", 
  Fired = "lefrd", 
  `Family illness` = "leinf",   
  Robbed = "lepcm",
  `Friend died` = "ledfr",
  `Relative died` = "ledrl",
  `Relative jailed` = "lejlf",
  `Home destroyed` = "ledhm",
  Moved = "lemvd",
  Hired = "lejob",
  Promoted = "leprm",
  Retired = "lertr",
  `Money gained` = "lefni",
  Pregnant = "leprg",
  Childbirth = "lebth",
  Married = "lemar"
)
```

<br>

#### Mental health  

HILDA includes comprehensive measures of mental health, such as the SF-36 from which the MHi-5 score, a measure of mental health, can be calculated [@ware1992mos; @mchorney1993mos; @mchorney1994mos; @ware2000sf], as well as the K10, a measure of psychological distress [@kessler2002short; @kessler2003].  

The MHi-5 comprises of five items dealing with ... etc .  

The K10 comprises of ten items dealing with ... etc .

The presence or absence of mental illness risk was defined by a K10 score > 21 or a MHi-5 score < 64 [@batterham2018assessing]. While neither is a diagnostic instrument, the probability is high that those who score above the K10 cut-point for very high distress have a common mental disorder [i.e., over 85%, @andrews2001interpreting], and both have good psychometric properties when identifying DSM-V disorders in a community sample [K10 AUC 0.877 and MHi-5 AUC 0.847, @batterham2018assessing].   

```{r create_illness_by_history}
mhi5 <- demographics %>%
  select(xwaveid, wave, ghmh) %>%
  mutate(ill = ghmh < 64) %>% # MHi-5 < 64
  group_by(xwaveid) %>%
  mutate(hist.ill = lag(ill)) %>%
  ungroup() %>%
  mutate(flag = ill & hist.ill) %>%
  filter(!flag) %>% # remove illness years which also have a history of illness
  na.omit() %>% # remove missing illness or missing history
  select(xwaveid, wave, ghmh, ill) 
```

```{r create_illness_by_k10}
k10 <- demographics %>%
  select(xwaveid, wave, pdk10s, pdk10rc) %>%
  mutate(ill = pdk10rc %in% 3:4) %>% # K10 > 21
  na.omit()

# exclude person-years with missing history
k10 <- left_join(
  select(mhi5, xwaveid, wave),
  k10, by = c("xwaveid", "wave")) %>%
  na.omit()
```

```{r join_predictors}
mf.k10 <- left_join(k10, events, by = c("xwaveid", "wave")) %>%
  na.omit() # should we replace_na for missing events here?

xwaveids.k10 <- unique(mf.k10$xwaveid)

mf.mhi5 <- left_join(mhi5, events, by = c("xwaveid", "wave")) %>%
  na.omit()

xwaveids.mhi5 <- unique(mf.mhi5$xwaveid)
```

HILDA includes repeated measurements of people in the same household, however the people in each household may vary from year to year. Each person is an independent measurement, however our units of observation were person-years. There were *n* = `r prettynum(nrow(mf.mhi5))` person-years (from *n* = `r prettynum(length(xwaveids.mhi5))` people) in the MHi-5 data between 2001 to 2020. There were *n* = `r prettynum(nrow(mf.k10))` person-years (from *n* = `r prettynum(length(xwaveids.k10))` people) in the K10 data between 2011 to 2020.  

<br>

#### Model development and evaluation  

We developed the weights for each life event using a logistic regression of mental illness risk (presence or absence) on the complete set of life events (plus yearly controls). Each regression was conducted in a cross-validated design using hold-out sampling, which randomly split the set of people in each data set into independent training and test sets. The random split was carried out 10 times to establish the stability of the resulting weights, and we report the median and range of weights from the ten splits. 

Model evaluation was performed by calculating discimrination and calibration metrics for the ten independent random splits. Model performance was summarised by the median and range of the resulting metric scores for each split.  

```{r model_formulas}
xnames <- select(events, starts_with("le")) %>%
  colnames()

formula.ill = as.formula(paste("ill ~", paste(xnames, collapse = " + ")))
formula.ill = update.formula(formula.ill, ~ . + wave)

formula.k10 = update.formula(formula.ill, pdk10s ~ .)
formula.mhi5 = update.formula(formula.ill, ghmh ~ .)
```

```{r mse_fun}
mse_vec <- function(truth, estimate, na_rm = TRUE, ...) {
  
  mse_impl <- function(truth, estimate) {
    truth = as.numeric(truth)
    sqrt(mean((truth - estimate) ^ 2))
  }
  
  metric_vec_template(
    metric_impl = mse_impl,
    truth = truth, 
    estimate = estimate,
    na_rm = na_rm,
    cls = "numeric",
    ...
  )
  
}

mse <- function(data, ...) {
  UseMethod("mse")
}

mse <- new_numeric_metric(mse, direction = "minimize")

mse.data.frame <- function(data, truth, estimate, na_rm = TRUE, ...) {
  
  metric_summarizer(
    metric_nm = "mse",
    metric_fn = mse_vec,
    data = data,
    truth = !! enquo(truth),
    estimate = !! enquo(estimate), 
    na_rm = na_rm,
    ...
  )
  
}
```

```{r crossvalidate_fun}

crossvalidate <- function(testdata, model) {
  
  predictions <- testdata %>%
    select(xwaveid, wave, ill) %>%
    mutate(pred = predict(model, 
                          newdata = testdata, 
                          type = "resp", 
                          allow.new.levels=T),
           ill.f = as.factor(ifelse(ill, "present", "absent")),
           ill.n = as.numeric(ill))
    
  
  proper_metrics <- metric_set(
  roc_auc,
  mn_log_loss)
  
  bind_rows(
    proper_metrics(predictions, truth = ill.f, pred, event_level = "second"),
    mse(predictions, truth = ill.n, estimate = pred)
  ) %>%
    select(metric = .metric, estimate = .estimate)

}
```
```{r calibration_fun}
calibration <- function(testdata, model) {
  
  testdata %>%
    select(xwaveid, wave, ill) %>%
    mutate(pred = predict(model, 
                          newdata = testdata, 
                          type = "resp"),
           ill = as.numeric(ill),
           decile = ntile(pred, 10)) %>%
    group_by(decile) %>%
    summarize(
      ill = mean(ill),
      pred = mean(pred)
    )
}
```

```{r k10_ill_fits}
# Fun to select training data for K10
k10_training_data <- function(.xwaveids, test=F) {
  
  if(!test) {
    filter(mf.k10, xwaveid %in% .xwaveids)} else {
      filter(mf.k10, xwaveid %notin% .xwaveids)}
}

# Sample size of K10 dataset
n.k10 <- length(unique(mf.k10$xwaveid))

# Fitting K10 > 21
if (file.exists("results/k10_ill_fits.rds")) {
  k10_ill_fits <- read_rds("results/k10_ill_fits.rds")
  
} else {
  # Create training data then fit K10 illness by life events and summed events
  k10_ill_fits <- tibble(
    iter = 1:10,
    xwaveids = map(1:10, .f = ~sample(unique(mf.k10$xwaveid), size = n.k10/2))
  ) %>%
    
    mutate(
      train = map(xwaveids, k10_training_data)
    ) %>%
    
    transmute(
      iter, xwaveids,
      
      fit.glm = map(train, ~{
        .x %>%
          glm(
            formula = formula.ill,
            data = .,
            family = binomial
          )}),
      
      fit.all = map(train, ~{
        .x %>%
          glm(
            formula = ill ~ All + wave,
            data = .,
            family = binomial
          )})
    )
  
  write_rds(k10_ill_fits, "results/k10_ill_fits.rds")
}
```

```{r k10_lm_fits}
# Fitting pdk10s
if (file.exists("results/k10_lm_fits.rds")) {
  k10_lm_fits <- read_rds("results/k10_lm_fits.rds")
  
} else {
  
  # Create training data then fit K10 scores by life events and summed events
  k10_lm_fits <- tibble(
    
    iter = 1:10,
    xwaveids = map(1:10, .f = ~sample(unique(mf.k10$xwaveid), size = n.k10/2))
  ) %>%
    
    mutate(
      train = map(xwaveids, k10_training_data),
    ) %>%
    
    transmute(
      iter, xwaveids,
      
      fit.lm = map(train, ~{
        .x %>%
          lm(
            formula = formula.k10,
            data = .
          )}),
      
      fit.qr = map(train, ~{
        .x %>%
          rq(
            formula = formula.k10,
            data = .,
            tau = c(0.2, 0.5, 0.8)
          )})
    )
  
  write_rds(k10_lm_fits, "results/k10_lm_fits.rds")
  
}
```

```{r mhi5_ill_fits}
# Fun to select training data for MHi-5
mhi5_training_data <- function(.xwaveids, test=F) {
  
  if(!test) {
    filter(mf.mhi5, xwaveid %in% .xwaveids)} else {
      filter(mf.mhi5, xwaveid %notin% .xwaveids)}
}

# Sample size of mhi5 dataset
n.mhi5 <- length(unique(mf.mhi5$xwaveid))

if (file.exists("results/mhi5_ill_fits.rds")) {
  mhi5_ill_fits <- read_rds("results/mhi5_ill_fits.rds")
  
} else {
  
  # Create training data then fit mhi5 illness by life events and sum
  mhi5_ill_fits <- tibble(
    
    iter = 1:10,
    xwaveids = map(1:10, .f = ~sample(unique(mf.mhi5$xwaveid), size = n.mhi5/2))
  ) %>%
    
    mutate(
      train = map(xwaveids, mhi5_training_data),
    ) %>%
    
    transmute(
      iter, xwaveids,
      
      fit.glm = map(train, ~{
        .x %>%
          glm(
            formula = formula.ill,
            data = .,
            family = binomial
          )}),
      
      fit.all = map(train, ~{
        .x %>%
          glm(
            formula = ill ~ All + wave,
            data = .,
            family = binomial
          )})
    )
  
  write_rds(mhi5_ill_fits, "results/mhi5_ill_fits.rds")
}
```

```{r mhi5_lm_fits}
# Fitting ghmh
if (file.exists("results/mhi5_lm_fits.rds")) {
  mhi5_lm_fits <- read_rds("results/mhi5_lm_fits.rds")
  
} else {
  
  # Create training data then fit mhi5 scores by life events and summed events
  mhi5_lm_fits <- tibble(
    iter = 1:10,
    xwaveids = map(1:10, .f = ~sample(unique(mf.mhi5$xwaveid), size = n.mhi5/2))
    ) %>%
    
    mutate(
      train = map(xwaveids, select_training_data),
      test = map(xwaveids, select_training_data, test=T)
      ) %>%
    
    transmute(
      iter,
      xwaveids,
      fit.lm = map(train, ~{
        .x %>%
          lm(
            formula = formula.mhi5,
            data = .
          )}),
      
      fit.qr = map(train, ~{
        .x %>%
          rq(
            formula = formula.mhi5,
            data = .,
            tau = c(0.2, 0.5, 0.8)
          )})
    )
  
  write_rds(mhi5_lm_fits, "results/mhi5_lm_fits.rds")
}
```

<br><br>

## Results  

(demographic tables to be added later if neccesary)  

<br><br>

#### Unconditional risk probability of each life-event  

We present the population-weighted estimates of the probability of mental illness risk given each major life event, adjusted for the Australian population. The population weights provided in HILDA are adjusted for age, sex, region-of-State, labour force status, marital status, and household composition for each person and year in Australia according to census data. For a description of the weight-adjustment, see [Table 4.28 in the HILDA manual](https://melbourneinstitute.unimelb.edu.au/hilda/for-data-users/user-manuals).  



##### Table 1a. Probability of mental illness risk (K10 > 21)   
```{r table_1a, echo=F}
# Population weights from HILDA for frequency of events in Australia
weights <- read_rds("data/hilda_sample_weights.rds")
 
if (!file.exists("results/Probability_table_1a.png")) {
  # Population weighted conditional probabilities
  left_join(k10, weights, by = c("xwaveid", "wave")) %>%
    select(xwaveid, wave, hhwtscs, ill) %>%
    left_join(select(events, -All), by = c("xwaveid", "wave")) %>%
    mutate(ill = as.numeric(ill)) %>%
    mutate(across(lebth:levio, ~ . * hhwtscs)) %>%
    group_by(wave) %>%
    summarize(across(lebth:levio, ~{sum(.x * ill) / sum(.x)})) %>%
    gather("event", "joint", lebth:levio) %>%
    rowwise() %>%
    mutate(wave = which(letters %in% wave) + 2000) %>%
    spread(wave, joint) %>%
    mutate(event = fct_recode(event, !!!named_events)) %>%
    flextable() %>%
    footnote(i = 1, j = 2:8,
             value = as_paragraph(
               c("conditional probability of K10 > 21")),
             ref_symbols = "1",
             part = "header", inline = T
    ) %>%
    autofit() %>%
    save_as_image(path = "results/Probability_table_1a.png")
}
```

<img src="results/Probability_table_1a.png" alt="Table 1a" style="height: 600px;"/>

<br>

##### Table 1b. Probability of mental illness risk (MHi-5 < 64)  
```{r table_1b, echo=F}

if (!file.exists("results/Probability_table_1b.png")) {
# Population weighted conditional probabilities
left_join(mhi5, weights, by = c("xwaveid", "wave")) %>%
  select(xwaveid, wave, hhwtscs, ill) %>%
  left_join(select(events, -All), by = c("xwaveid", "wave")) %>%
  mutate(ill = as.numeric(ill)) %>%
  mutate(across(lebth:levio, ~ . * hhwtscs)) %>%
  group_by(wave) %>%
  summarize(across(lebth:levio, ~{sum(.x * ill) / sum(.x)})) %>%
  gather("event", "joint", lebth:levio) %>%
  rowwise() %>%
  mutate(wave = which(letters %in% wave) + 2000) %>%
  spread(wave, joint) %>%
  mutate(event = fct_recode(event, !!!named_events)) %>%
  flextable() %>%
  footnote(i = 1, j = 2:20,
           value = as_paragraph(
             c("conditional probability of MHi-5 < 64")),
           ref_symbols = "1",
           part = "header", inline = T
           ) %>%
  autofit() %>%
  save_as_image(path = "results/Probability_table_1b.png")
}
```

<img src="results/Probability_table_1b.png" alt="Table 1a" style="height: 400px;"/>


<br><br>

#### Conditional risk weights for each life-event 

Each logistic regression of mental illness risk on life events included all life events as well as yearly controls, so the coefficients represent the _unique_ (conditional?) effect of each life event on the log odds of risk.    

```{r k10_ill_coefficients, echo=F}
k10_ill_coefs <- k10_ill_fits %>%
  transmute(
    iter,
    coefs = map(.x = fit.glm, ~tidy(.x) %>% filter(str_starts(term, "le")))
    ) %>%
  unnest(cols = coefs) %>%
  select(iter, term, estimate) %>%
  group_by(term) %>%
  summarize(
    min = min(estimate),
    lower = quantile(estimate, 0.1),
    est = quantile(estimate, 0.5),
    upper = quantile(estimate, 0.9),
    max = max(estimate)
  ) 
```

```{r mhi5_ill_coefficients, echo=F}
mhi5_ill_coefs <- mhi5_ill_fits %>%
  transmute(
    iter,
    coefs = map(.x = fit.glm, ~tidy(.x) %>% filter(str_starts(term, "le")))
    ) %>%
  unnest(cols = coefs) %>%
  select(iter, term, estimate) %>%
  group_by(term) %>%
  summarize(
    min = min(estimate),
    lower = quantile(estimate, 0.1),
    est = quantile(estimate, 0.5),
    upper = quantile(estimate, 0.9),
    max = max(estimate)
  ) 
```

##### Figure 1. Cross-validated weights of mental illness risk for life-events
```{r figure_1, fig.dim=c(7, 7.5), echo=F}
bind_rows(k10_ill_coefs %>% mutate(yvar = "K10"),
          mhi5_ill_coefs %>% mutate(yvar = "MHi-5")) %>%
  group_by(term) %>%
  mutate(order = mean(est)) %>%
  ungroup() %>%
  mutate(event = fct_recode(term, !!!named_events),
         event = fct_reorder(event, order)) %>%
  ggplot(aes(x = est, y = event, color = yvar)) +
    geom_pointrange(aes(xmin = min, xmax = max),
                    position = position_dodge(width = 0.5)) +
    labs(subtitle = "Median weight and range (min-max)",
         y = "", x = "\u03B2 weight (log odds)") +
    theme_minimal() +
    theme(legend.position = "none") +
    scale_color_manual(values = c("black", "grey75"))
```

*Figure 1 legend: The median and range of the conditional weights from the ten training models predicting either K10 > 21 (black) or MHi-5 < 64 (grey). Each weight represents the conditional effect of the life-event on mental health risk from a logistic regression including all life-events and wave controls.*   


<br><br>

#### Linear mental health changes for each quartile  

Quantile regression was conducted to compare the amount of change in mental health score (K10 or MHi-5) between different quartiles of the response variable. Each regression included all life events (and yearly controls) so the coefficients ($\beta$s) represent the amount of unique change after each life event in K10 or MHi-5 units.  

```{r k10_lm_coefficients, echo=F}
tidy.rqs <- function(rqs) {
  
  coef(rqs) %>%
    as_tibble(rownames = "term")

}


k10_lm_coefs <- k10_lm_fits %>%
  transmute(
    iter,
    coefs.lm = map(.x = fit.lm, ~tidy(.x) %>% filter(str_starts(term, "le"))),
    coefs.qr = map(.x = fit.qr, ~tidy.rqs(.x) %>% 
                     filter(str_starts(term, "le")) %>%
                     gather("tau", "estimate", -term)
                   )
    )

k10_lm_coefs_summary <- bind_rows(
  
  k10_lm_coefs %>%
    select(iter, coefs.lm) %>%
    unnest(cols = coefs.lm) %>%
    select(iter, term, estimate) %>%
    mutate(tau = "OLS"),
  
  k10_lm_coefs %>%
    select(iter, coefs.qr) %>%
    unnest(cols = coefs.qr) 
  
  ) %>%
  
  group_by(term, tau) %>%
  summarize(
    min = min(estimate),
    lower = quantile(estimate, 0.1),
    est = quantile(estimate, 0.5),
    upper = quantile(estimate, 0.9),
    max = max(estimate)
  ) 
```

```{r mhi5_lm_coefficients, echo=F}
mhi5_lm_coefs <- mhi5_lm_fits %>%
  transmute(
    iter,
    coefs.lm = map(.x = fit.lm, ~tidy(.x) %>% filter(str_starts(term, "le"))),
    coefs.qr = map(.x = fit.qr, ~tidy.rqs(.x) %>% 
                     filter(str_starts(term, "le")) %>%
                     gather("tau", "estimate", -term)
                   )
    )

mhi5_lm_coefs_summary <- bind_rows(
  
  mhi5_lm_coefs %>%
    select(iter, coefs.lm) %>%
    unnest(cols = coefs.lm) %>%
    select(iter, term, estimate) %>%
    mutate(tau = "OLS"),
  
  mhi5_lm_coefs %>%
    select(iter, coefs.qr) %>%
    unnest(cols = coefs.qr) 
  
  ) %>%
  
  group_by(term, tau) %>%
  summarize(
    min = min(estimate),
    lower = quantile(estimate, 0.1),
    est = quantile(estimate, 0.5),
    upper = quantile(estimate, 0.9),
    max = max(estimate)
  ) 
```

##### Figure 2. Linear regression weight of each life-event on mental health score
```{r figure_2, fig.dim=c(7, 9), echo=F}
bind_rows(
  k10_lm_coefs_summary %>% mutate(yvar = "K10"),
  mhi5_lm_coefs_summary %>% mutate(yvar = "MHi-5")
  ) %>%
  group_by(term) %>%
  mutate(order = mean(abs(est))) %>%
  ungroup() %>%
  mutate(event = fct_recode(term, !!!named_events),
         event = fct_reorder(event, order),
         tau = fct_recode(tau, OLS = "OLS", 
                          `Lower qrtl` = "tau= 0.2",
                          Median = "tau= 0.5",
                          `Upper qrtl` = "tau= 0.8")) %>%
  
  filter(tau != "OLS") %>% # remove OLS for legibility
  
  ggplot(aes(x = est, y = event, color = tau)) +
    geom_vline(aes(xintercept = 0)) +
    geom_pointrange(aes(xmin = min, xmax = max),
                    position = position_dodge(width = 0.5)) +
    labs(subtitle = "Median weight and range (min-max)",
         y = "", x = "\u03B2 weight") +
    scale_color_manual(values = c("grey50", blues9[3], blues9[5], blues9[8])) +
    facet_wrap(~yvar, scales = "free_x") +
    theme_minimal() +
    theme(legend.title = element_blank(),
          legend.position = "bottom")
```

*Figure 2 legend: The median and range of the coefficients from the ten training models of each life event on K10 score (left panel) or MHi-5 score (right panel). Each weight represents the unique effect of the life-event on mental health score from a quantile regression including all life-events and yearly controls.*  


<br><br>

### Discrimination  

Discrimination is the ability of the predicted risk score to differentiate between people at risk of mental illness from people who are not at risk. We used _strictly proper scoring rules_ [@merkle2013choosing] to compare the probablistic predictions from different models, as these do not require an arbitrary probability threshold and make full use of the entire range of predicted probabilities [@harrell2015regression]. A _proper_ concordance- or c-index (AUC) was calculated to represent the ability of the model to differentiate between those who are or are not at risk of mental illness, where a value of 0.5 represents chance and 1 represents perfect discrimination. We also calculate the root mean square error (equivalent to a _root_ Brier score in this two-class problem) and the mean log loss where lower scores are better. Mean log loss gives more credit to extreme correct predictions, but if the model assigns a certain (i.e., 0 or 1) but incorrect probability to any prediction then it will score infinity [@kruppa2014theory; @kruppa2014application].  

<br>

#### Risk of mental illness discrimination  

```{r k10_ill_discrimination, echo=F}
if (file.exists("results/k10_ill_discrimination.rds")) {
  k10_ill_discrimination <- read_rds("results/k10_ill_discrimination.rds")
  
} else {
  
  bind_rows(
    
    k10_ill_fits %>%
      transmute(
        iter,
        test = map(xwaveids, k10_training_data, test=T),
        results = map2(.x = test, .y = fit.glm, ~crossvalidate(.x, .y))
      ) %>%
      unnest(cols = results) %>%
      mutate(model = "weighted"),
    
    k10_ill_fits %>%
      transmute(
        iter,
        test = map(xwaveids, k10_training_data, test=T),
        results = map2(.x = test, .y = fit.all, ~crossvalidate(.x, .y))
      ) %>%
      unnest(cols = results) %>%
      mutate(model = "unweighted")
    
  ) %>%
    spread(model, estimate) %>%
    mutate(
      adv = case_when(
        metric %in% c("mn_log_loss", "mse") ~ unweighted - weighted,
        TRUE ~ weighted - unweighted),
      n_id = map_dbl(test, ~{length(unique(.x$xwaveid))})
    ) %>%
    select(-test) %>%
    group_by(metric) -> k10_ill_discrimination
  
  write_rds(k10_ill_discrimination, "results/k10_ill_discrimination.rds")
  
}
```

##### Table 2. K10 risk model discrimination performance for weighted and unweighted life events
```{r table_2, echo=F}
print_ill_discrimination_table <- function(.ill_discrimination) {
  
  tb1 <- summarize(.ill_discrimination,
    min = min(weighted),
    lower = quantile(weighted, 0.05),
    median = quantile(weighted, 0.5),
    upper = quantile(weighted, .95),
    max = max(weighted)
  ) %>%
  mutate(across(where(is.double), ~round(., 3))) %>%
  transmute(
    metric,
    `Weighted model` = paste0(median, " [", min, ", ", max, "]")
  ) 

tb2 <- summarize(.ill_discrimination,
    min = min(unweighted),
    lower = quantile(unweighted, 0.05),
    median = quantile(unweighted, 0.5),
    upper = quantile(unweighted, .95),
    max = max(unweighted)
  ) %>%
  mutate(across(where(is.double), ~round(., 3))) %>%
  transmute(
    metric,
    `Unweighted model` = paste0(median, " [", min, ", ", max, "]")
  ) 

tb3 <- summarize(.ill_discrimination,
    min = min(adv),
    lower = quantile(adv, 0.05),
    median = quantile(adv, 0.5),
    upper = quantile(adv, .95),
    max = max(adv)
  ) %>%
  mutate(across(where(is.double), ~round(., 3))) %>%
  transmute(
    metric,
    `Weight advantage` = paste0(median, " [", min, ", ", max, "]")
  ) 

left_join(tb1, tb2, by = "metric") %>%
  left_join(tb3, by = "metric") %>%
  mutate(metric = recode(metric, mse = "rmse")) %>%
  flextable() %>%
  footnote(i = 1, j = 2:4,
           value = as_paragraph(
             c("median [min, max] score of ten independent test samples")),
           ref_symbols = "1",
           part = "header", inline = T
           )
}

if (!file.exists("results/K10ill_table_2.png")) {
  print_ill_discrimination_table(k10_ill_discrimination) %>%
    autofit() %>%
    save_as_image(path = "results/K10ill_table_2.png")
}
```

<img src="results/K10ill_table_2.png" alt="Table 1a" style="height: 125px;"/>


```{r mhi5_ill_discrimination, echo=F}
if (file.exists("results/mhi5_ill_discrimination.rds")) {
  mhi5_ill_discrimination <- read_rds("results/mhi5_ill_discrimination.rds")
  
} else {
  
  bind_rows(
    
    mhi5_ill_fits %>%
      transmute(
        iter,
        test = map(xwaveids, mhi5_training_data, test=T),
        results = map2(.x = test, .y = fit.glm, ~crossvalidate(.x, .y))
      ) %>%
      unnest(cols = results) %>%
      mutate(model = "weighted"),
    
    mhi5_ill_fits %>%
      transmute(
        iter,
        test = map(xwaveids, mhi5_training_data, test=T),
        results = map2(.x = test, .y = fit.all, ~crossvalidate(.x, .y))
      ) %>%
      unnest(cols = results) %>%
      mutate(model = "unweighted")
    
  ) %>%
    spread(model, estimate) %>%
    mutate(adv = case_when(
      metric %in% c("mn_log_loss", "mse") ~ unweighted - weighted,
      TRUE ~ weighted - unweighted),
      n_id = map_dbl(test, ~{length(unique(.x$xwaveid))})
    ) %>%
    select(-test) %>%
    group_by(metric) -> mhi5_ill_discrimination
  
  write_rds(mhi5_ill_discrimination, "results/mhi5_ill_discrimination.rds")
  
}
```

<br><br>

##### Table 3. MHi-5 risk model discrimination performance for weighted and unweighted life events
```{r table_3, echo=F}
if (!file.exists("results/mhi5ill_table_3.png")) {
  print_ill_discrimination_table(mhi5_ill_discrimination) %>%
    autofit() %>%
    save_as_image(path = "results/mhi5ill_table_3.png")
}
```

<img src="results/mhi5ill_table_3.png" alt="Table 3" style="height: 125px;"/>

<br><br>

**Key points**  

- Discrimination by unweighted or weighted life events was low (i.e, AUC ~ 0.6)
- Weighted life events provided better discrimination than unweighted in every independent test sample  

<br><br>

#### Mental health score change discrimination  

Quantile regression predictions were compared with OLS predictions to determine whether differences in baseline levels of mental health explained more variance in the effect of life events on mental health score. Quantile and OLS models were compared for ten random splits and the median and range of discrimination scores are presented.  

`ccc` (concordance correlation coefficient) is a metric of both consistency/correlation and accuracy, while metrics such as `rmse` (root mean square error) are strictly for accuracy and metrics such as `rsq` (r-squared) are strictly for consistency/correlation.  

```{r lm_discrimination_fun, include=F}
predict.qrs <- function(testdata, model) {
  
  bind_cols(
    select(testdata, xwaveid, wave, y = 3),
    predict(model, newdata = testdata) %>% 
      as_tibble()
    ) %>%
  mutate(pct = percent_rank(y)) %>%
  gather("key", "pred", `tau= 0.2`:`tau= 0.8`) %>%
  mutate(tau = extract_numeric(key)) %>%
  arrange(xwaveid, wave) %>%
  mutate(diff = abs(tau - pct)) %>%
  group_by(xwaveid, wave) %>%
  slice_min(diff, with_ties = F) %>%
  ungroup() %>%
  select(-diff, -key)
  
}


lincrossvalidate <- function(testdata, model) {
  
  if (class(model) != "rqs") {
    predictions <- testdata %>%
      select(xwaveid, wave, y = 3) %>%
      mutate(pred = predict(model, 
                            newdata = testdata, 
                            type = "resp")) 
  } else {
    predictions <- predict.qrs(testdata, model)
  }
  
  
  numeric_metrics <- metric_set(rmse, rsq, ccc)
  
  numeric_metrics(predictions, truth = y, pred) %>%
    select(metric = .metric, estimate = .estimate)
  
}
```

```{r k10_lin_discrimination, include=F}
if (file.exists("results/k10_lin_discrimination.rds")) {
  k10_lin_discrimination <- read_rds("results/k10_lin_discrimination.rds")
  
} else {
  
  bind_rows(
    k10_lm_fits %>%
      mutate(
        test = map(xwaveids, k10_training_data, test=T),
        results = map2(.x = test, .y = fit.lm, ~lincrossvalidate(.x, .y))
      ) %>% #pull(test, 1)
      select(iter, results) %>%
      unnest(cols = results) %>%
      mutate(model = "lm"),
    
    k10_lm_fits %>%
      mutate(
        test = map(xwaveids, k10_training_data, test=T),
        results = map2(.x = test, .y = fit.qr, ~lincrossvalidate(.x, .y))
      ) %>%
      select(iter, results) %>%
      unnest(cols = results) %>%
      mutate(model = "qr")
  ) %>%
    
    spread(model, estimate) %>%
    mutate(
      adv = case_when(
        metric %in% c("rmse") ~ lm - qr,
        TRUE ~ qr - lm),
    ) %>%
    group_by(metric) -> k10_lin_discrimination
  
  write_rds(k10_lin_discrimination, "results/k10_lin_discrimination.rds")
  
}
```

##### Table 4. K10 model discrimination for OLS and quantile regression  
```{r table_4, include=F}
print_lin_discrimination_table <- function(.lin_discrimination) {
  
  tb1 <- summarize(.lin_discrimination,
    min = min(lm),
    median = quantile(lm, 0.5),
    max = max(lm)
  ) %>%
  mutate(across(where(is.double), ~round(., 2))) %>%
  transmute(
    metric,
    `OLS` = paste0(median, " [", min, ", ", max, "]")
  ) 

tb2 <- summarize(.lin_discrimination,
    min = min(qr),
    median = quantile(qr, 0.5),
    max = max(qr)
  ) %>%
  mutate(across(where(is.double), ~round(., 2))) %>%
  transmute(
    metric,
    `Quantile regression` = paste0(median, " [", min, ", ", max, "]")
  ) 

tb3 <- summarize(.lin_discrimination,
    min = min(adv),
    median = quantile(adv, 0.5),
    max = max(adv)
  ) %>%
  mutate(across(where(is.double), ~round(., 2))) %>%
  transmute(
    metric,
    `Quantile advantage` = paste0(median, " [", min, ", ", max, "]")
  ) 

left_join(tb1, tb2, by= "metric") %>%
  left_join(tb3, by = "metric") %>%
  flextable() %>%
  footnote(i = 1, j = 2:4,
           value = as_paragraph(
             c("median [min, max] score of ten independent test samples")),
           ref_symbols = "1",
           part = "header", inline = T
           )
}

if (!file.exists("results/K10lm_table_4.png")) {
  print_lin_discrimination_table(k10_lin_discrimination) %>%
    autofit() %>%
    save_as_image(path = "results/K10lm_table_4.png")
}
```

<img src="results/K10lm_table_4.png" alt="Table 4" style="height: 150px;"/>

<br><br>

```{r mhi5_lin_discrimination, include=F}
if (file.exists("results/mhi5_lin_discrimination.rds")) {
  mhi5_lin_discrimination <- read_rds("results/mhi5_lin_discrimination.rds")
  
} else {
  
  bind_rows(
    mhi5_lm_fits %>%
      mutate(
        test = map(xwaveids, mhi5_training_data, test=T),
        results = map2(.x = test, .y = fit.lm, ~lincrossvalidate(.x, .y))
      ) %>% 
      select(iter, results) %>%
      unnest(cols = results) %>%
      mutate(model = "lm"),
    
    mhi5_lm_fits %>%
      mutate(
        test = map(xwaveids, mhi5_training_data, test=T),
        results = map2(.x = test, .y = fit.qr, ~lincrossvalidate(.x, .y))
      ) %>%
      select(iter, results) %>%
      unnest(cols = results) %>%
      mutate(model = "qr")
  ) %>%
    
    spread(model, estimate) %>%
    mutate(
      adv = case_when(
        metric %in% c("rmse") ~ lm - qr,
        TRUE ~ qr - lm)
    ) %>%
    group_by(metric) -> mhi5_lin_discrimination
  
  write_rds(mhi5_lin_discrimination, "results/mhi5_lin_discrimination.rds")
}
```

##### Table 5. MHi-5 model discrimination for OLS and quantile regression  
```{r table_5, include=F}
if (!file.exists("results/mhi5lm_table_5.png")) {
  print_lin_discrimination_table(mhi5_lin_discrimination) %>%
    autofit() %>%
    save_as_image(path = "results/mhi5lm_table_5.png")
}
```

<img src="results/mhi5lm_table_5.png" alt="Table 5" style="height: 150px;"/>

<br>

**Key points**  

- Prediction by OLS is poor (r-squared < 0.05)
- The quantile regression with different predictions for each quartile provides moderate to good performance (e.g., r-squared > 0.6)  


<br>

<br><br>

### Calibration    

Calibration refers to how closely the predicted mental illness risk agrees with the observed mental illness risk [@moons2015transparent], and was assessed by calculating the ratio of predicted to observed risk over low to high risk deciles in our dataset. Calibration is better as the ratio approaches 1:1. The quality of the risk score predictions was assessed by calculating risk scores in each each of the ten independent (random split) test sets, and then plotting the mean observed proportions versus mean predicted probabilities across deciles.  

##### Figure 3. 
```{r k10_ill_calibration, echo=F}
bind_rows(
  
  k10_ill_fits %>%
    transmute(
      iter,
      test = map(xwaveids, k10_training_data, test=T),
      results = map2(.x = test, .y = fit.glm, ~calibration(.x, .y))
      ) %>%
    unnest(cols = results) %>%
    mutate(model = "weighted"),
  
  k10_ill_fits %>%
    transmute(
      iter,
      test = map(xwaveids, k10_training_data, test=T),
      results = map2(.x = test, .y = fit.all, ~calibration(.x, .y))
      ) %>%
    unnest(cols = results) %>%
    mutate(model = "unweighted")
  ) %>%
  group_by(model, decile, ) %>%
  summarize(
    `Predicted rate` = mean(pred),
    `Observed rate` = mean(ill)
  ) %>%
  ggplot(aes(x = `Predicted rate`, y = `Observed rate`)) +
    geom_abline(slope = 1, intercept = 0, size = .1, linetype = "dashed") +
    geom_point() +
    geom_line(aes(linetype = model)) + 
    theme_linedraw() +
    theme(panel.border = element_rect(color = "grey80"),
          axis.ticks = element_line(color = "grey80"),
          legend.title = element_blank()) +
    scale_color_manual(values = c("black", "grey50")) -> p1
```

```{r mhi5_ill_calibration, echo=F}
bind_rows(
  
  mhi5_ill_fits %>%
    transmute(
      iter,
      test = map(xwaveids, mhi5_training_data, test=T),
      results = map2(.x = test, .y = fit.glm, ~calibration(.x, .y))
      ) %>%
    unnest(cols = results) %>%
    mutate(model = "weighted"),
  
  mhi5_ill_fits %>%
    transmute(
      iter,
      test = map(xwaveids, mhi5_training_data, test=T),
      results = map2(.x = test, .y = fit.all, ~calibration(.x, .y))
      ) %>%
    unnest(cols = results) %>%
    mutate(model = "unweighted")
    ) %>%
  group_by(model, decile, ) %>%
  summarize(
    `Predicted rate` = mean(pred),
    `Observed rate` = mean(ill)
  ) %>%
  ggplot(aes(x = `Predicted rate`, y = `Observed rate`)) +
    geom_abline(slope = 1, intercept = 0, size = .1, linetype = "dashed") +
    geom_point() +
    geom_line(aes(linetype = model)) + 
    theme_linedraw() +
    theme(panel.border = element_rect(color = "grey80"),
          axis.ticks = element_line(color = "grey80"),
          legend.title = element_blank()) +
    scale_color_manual(values = c("black", "grey50")) -> p2
```

```{r figure_3, echo=F}
p1 + p2 + plot_layout(guides = 'collect') & theme(legend.position = "top")
```

<br><br>

**Key points**  

- Calibration is very similar between weighted and unweighted life events (dotted line vs solid line)
- Calibration is very similar between K10 and MHi-5 risk of mental illness (left vs right panel)




<br><br>


#### To do  

1. We could likely improve the risk weights by calculating them for each K10 risk category  
2. Net reclassication improvement (NRI) is the net proportion of events reclassified correctly plus the net proportion of nonevents reclassified correctly
2. Reclassification table across different risk categories (show how many individuals are reclassified from low to high risk)
3. Number needed to treat (NNT) improvement  

*(below could be added somewhere)*  
We also report (improper) classification accuracy metrics which may be more familiar in a clinical context such as sensitivity, specificity and number-needed-to-treat (NNT). The NNT is the average number of patients who need to be treated to prevent one additional bad outcome (e.g. the number of patients that need to be treated for one of them to benefit compared with a control in a clinical trial). It is defined as the inverse of the absolute risk reduction: NNT = 1 / (*I*<sub>u</sub> — *I*<sub>e</sub>), where *I*<sub>e</sub> is the incidence in the treated (exposed) group, and *I*<sub>u</sub> is the incidence in the control (unexposed) group. However in this diagnostic/classification context it isn't clear what would represent that quantity. The inverse of the Youden index (1/j) has been defined as the “number needed to diagnose” (NND), that is, the number of patients who need to be examined in order to correctly detect one person with the disease of interest in a study population of persons with and without the known disease [@linn2006new]. The same authors also proposed a predictive summary index (PSI = PPV + NPV - 1) to represent the gain in certainty of diagnosis. It's inverse (1/PSI) represents the number of patients who need to be examined in order to correctly _predict_ the diagnosis of one person (NNP). Whilst NND is insensitive to variation in disease prevalence, since it depends entirely on sensitivity and specificity, NNP is dependent on prevalence and therefore may be a better descriptor of diagnostic tests in patient populations with different prevalence of disease. 

<br><br>

## Discussion  

Our study provided frequencies of major life events in Australia for a large sample of the population. Based on the large and representative data set, these results represent reliable data without common selection bias for specific subpopulations, which is necessary for planning and designing public health services.  

We also report the predictive associations between weighted and unweighted life events and the risk of mental illness. The use of weights in life event scales has been debated since 1960s. Originally generic weights rather than subjective weights were promoted on the grounds that generic weights are _a priori_ independent from the experience of the event, and so can predict consequences of the stress exposure such as the risk of poor health. Here we are proposing a set of generic weights that are based on the average experience of the event from an independent and representative sample of the population.  

We demonstrate the use of these empirical weights improves the predictive value of a life-event scale for mental illness risk, relative to an unweighted scale, however both weighted and unweighted scales had low discriminative performance with AUC generally not exceeding 0.6. However it is likely the risk of mental illness after major life-events varies with baseline mental health, and once this is captured then risk weights can account for substantially more variation.  

Problems in defining and sampling the relevant population for stressful life events are often present in life events research [see @dohrenwend1974stressful], as _post-hoc_ selection of people who experienced a major life event is likely to result in biased estimates. That is, people who experienced a significant response to the life event are more likely to be selected by such post-hoc methods, even if only because they are more likely to remember the event than someone who was unperturbed. One strength of the present study is the use of probabilistic sampling of the Australian population in HILDA, which avoids any selection bias of the response. Furthermore, the relationship between a stressful life event and a health outcome can be interpreted as causal when exposure to the event occurred for reasons that are random with respect to the outcome [@kessler1997effects], which is the case here under HILDA's probabilistic sampling method. However selection bias may still exist if some victims are less likely to report an event than others (e.g., homelessness, sexual assault, or severely affected sufferers).  

One limitation of using a life event schedule as employed here, is that events are broad and vaguely defined. For instance, there may be important differences in the response to divorce after an amicable seperation versus after marital conflict or infidelity [@dohrenwend2006inventorying]. However estimating the population response to more detailed events is difficult in the currently available datasets, in which the items recording life events are broad and ill-defined for pragmatic reasons.  



<br><br>

## Supplementary  


##### Figure S1. Frequency of each major life event in Australia between 2001-2020
```{r frequency_uncertainty, echo=F}
prop.error <- function(.v, lo=T) {

  if (all(is.na(.v))) {
    return(0)
  } else {
    xsum = sum(.v, na.rm=T)
    nsum = sum(!is.na(.v))

    ans <- prop.test(x = xsum, n = nsum)

    if (lo) {
      return(ans$estimate - ans$conf.int[1])

    } else {
      return(ans$conf.int[2] - ans$estimate)
    }
  }
}

lo_err <- events %>%
  group_by(wave) %>%
  summarize(across(where(is.numeric), ~prop.error(.))) %>%
  rowwise() %>%
  mutate(wave = which(letters == wave) + 2000) %>%
  ungroup() %>%
  gather(key = "event", value = "lo", lebth:levio)

hi_err <- events %>%
  group_by(wave) %>%
  summarize(across(where(is.numeric), ~prop.error(., lo=F))) %>%
  rowwise() %>%
  mutate(wave = which(letters == wave) + 2000) %>%
  ungroup() %>%
  gather(key = "event", value = "hi", lebth:levio)
```

```{r figure_s1, fig.dim = c(9, 9), echo=F, warning=F}
# Population weighted frequencies
frequencies <- events %>%
  left_join(select(weights, -hhwtsc), by = c("xwaveid", "wave")) %>%
  mutate(across(lebth:levio, ~ . * hhwtscs)) %>%
  select(-hhwtscs) %>%
  group_by(wave) %>%
  summarize(across(where(is.numeric), mean, na.rm=T)) 

# Plot frequencies + uncertainty
frequencies %>%
  rowwise() %>%
  mutate(wave = which(letters == wave) + 2000) %>%
  ungroup() %>%
  gather(key = "event", value = "est", lebth:levio) %>%
  filter(event %notin% "ledhm") %>%
  # left_join(lo_err, by = c("wave", "event")) %>%
  # left_join(hi_err, by = c("wave", "event")) %>%
  mutate(
    event = fct_recode(event, !!!named_events),
    event = fct_reorder(event, est, .fun = max)) -> fig1

ggplot(fig1, aes(x = wave, y = est)) +
  # geom_ribbon(aes(ymin = est - lo, ymax = est + hi), alpha = 0.3) +
  geom_line(group = 1, color=blues9[5], size=1) +
  facet_wrap(~fct_rev(event)) +
  labs(subtitle = "Population-weighted proportion",
       x = "", y = "",
       caption = "Source: Household and Income Labour Dynamics in Australia (HILDA) survey") +
  theme_minimal() +
  theme(
    panel.grid.minor = element_blank(),
    panel.grid.major.x = element_blank() 
  )
```

<br>

The most frequent major life event is a illness or injury in a close family member (Family illness) or moving home (Moved) for approximately 15 percent of Australians in any one-year period, while the least frequent is being detained in jail (Jailed) for less than 1 percent of Australians. The frequency of some events appear to have declined in the last two decades, including family illness (or injury), moving home (Moved), and starting a new job (Hired). There are no apparent increasing trends in the frequency of any event. It is unclear whether these temporal trends reflect real change in the Australian population or changes in the survey sample as the respondents age over time.   

<br><br>

## References  



